

{{< include ../math.qmd >}}


# Probability theory


::: {#def-randomvector}
## Random vector
Given a random experiment with a sample space $\mathcal C$, consider two random variables $X_1$ and $X_2$, which assign to each element 
:::


::: {#def-cdf}
## Joint Cumulative Distribution Function
This is also called *the joint cumulative distribution function* of $(X_1, X_2)$.
$$
F_{X_1,X_2}(x_1,x_2)=\pr\sqb{\set{X_1\leq x_1}\cap\set{X_2\leq x_2}},
$$
:::


::: {#def-pdf}
## Joint Probability mass function (pmf)
discrete random vector: 
$$
p_{X_1,X_2}(x_1,x_2)=\pr\sqb{X_1=x_1,X_2=x_2}.
$$

:::

::: {#def-cdf}
## Joint Cumulative Distribution Function
This is also called *the joint cumulative distribution function* of $(X_1, X_2)$.
$$
F_{X_1,X_2}(x_1,x_2)=\int_{-\infty}^{x_1}\int_{-\infty}^{x_2}f_{X_1,X_2}(w_1,w_2)\dl3w_1\dl3w_2,
$$
:::




::: {#def-marginal}
$$
f
$$
:::


::: {#def-conditionaldistribution}
$$
f_{X_1\mid X_2}(x_1\mid x_2)=\frac{f_{X_1,X_2}(x_1,x_2)}{f_{X_1}(x_1)}=\frac{f_{X_1,X_2}(x_1,x_2)}{\int_{-\infty}^{\infty} f_{X_1,X_2}(x_1,w)\dl3w}.
$$
:::

::: {#def-pdf}
## Joint Probability density function (pdf)
discrete random vector: 
$$
f_{X_1,X_2}(x_1,x_2)=\frac{\partial^2F_{X_1,X_2}(x_1,x_2)}{\partial x_1\partial x_2}
$$

:::

## joint distribution

$\distbeta(a,b)$


## 


::: {#thm-bayesthm}
$$
f_{X\mid Y=y}(x)=\frac{f_{Y\mid X=x}(y\mid x)f_X(x)}{f_Y(y)}
$$
:::



::: {.callout-note}
$f_{X\mid Y}(x\mid y)$ is a pdf w.r.t $X$, not a pdf w.r.t $Y$.
:::